{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "os.chdir('../Utils/')\n",
    "import featureGenerator\n",
    "from featureGenerator import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features and Response Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/Desktop/Stanford/MSE 448/448 Project/Utils/featureGenerator.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data['Response'] = response_col\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../ProjectData/'\n",
    "in_path = data_dir+'msft-orderbook.csv'\n",
    "out_path = data_dir+'msft-orderbook-v2.csv'\n",
    "\n",
    "createFeatures(in_path, out_path, response_type = 'Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(out_path)\n",
    "data = data.drop(['datetime', 'direct.last_SRO'], axis = 1)\n",
    "dataset = data.values\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15677 7722\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=5):\n",
    "    dataY = get_one_hot(dataset[look_back+1:,dataset.shape[1]-1].astype(int).reshape(-1),3)\n",
    "    dataX = []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :]    \n",
    "        dataX.append(a)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert response variable to one-hot vectors\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15671, 5, 69)\n",
      "(15671, 3)\n"
     ]
    }
   ],
   "source": [
    "look_back = 5\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 9s - loss: 4.5691 - acc: 0.0784\n",
      "Epoch 2/5\n",
      " - 7s - loss: 4.5015 - acc: 0.0471\n",
      "Epoch 3/5\n",
      " - 7s - loss: 4.5047 - acc: 0.0471\n",
      "Epoch 4/5\n",
      " - 7s - loss: 4.5024 - acc: 0.0471\n",
      "Epoch 5/5\n",
      " - 7s - loss: 4.4980 - acc: 0.0471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bd2cdd8>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {0 : 1.,\n",
    "    1: 25.,\n",
    "    2: 50.} \n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(5,69), return_sequences=False))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.fit(trainX, trainY, epochs=5,  batch_size=10, verbose=2, class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = model.predict(trainX)#.argmax(axis=-1)\n",
    "#pd.Series(preds).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21170\n",
       "2     1126\n",
       "1     1103\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6.52900009e+01,   6.53199997e+01,   5.31000000e+04, ...,\n",
       "           1.16178688e+06,   5.00000000e+02,   2.00000000e+00],\n",
       "        [  6.52900009e+01,   6.53099976e+01,   2.41200000e+03, ...,\n",
       "           6.40067850e+06,   1.00000000e+02,   2.00000000e+00],\n",
       "        [  6.52300034e+01,   6.52500000e+01,   2.12300000e+03, ...,\n",
       "           6.99807200e+06,   5.00000000e+00,   2.00000000e+00],\n",
       "        [  6.51800003e+01,   6.52099991e+01,   2.76000000e+02, ...,\n",
       "           7.35185550e+06,   1.00000000e+02,   2.00000000e+00],\n",
       "        [  6.51600037e+01,   6.51800003e+01,   2.72000000e+02, ...,\n",
       "           7.49566600e+06,   2.80000000e+01,   0.00000000e+00]],\n",
       "\n",
       "       [[  6.52900009e+01,   6.53099976e+01,   2.41200000e+03, ...,\n",
       "           6.40067850e+06,   1.00000000e+02,   2.00000000e+00],\n",
       "        [  6.52300034e+01,   6.52500000e+01,   2.12300000e+03, ...,\n",
       "           6.99807200e+06,   5.00000000e+00,   2.00000000e+00],\n",
       "        [  6.51800003e+01,   6.52099991e+01,   2.76000000e+02, ...,\n",
       "           7.35185550e+06,   1.00000000e+02,   2.00000000e+00],\n",
       "        [  6.51600037e+01,   6.51800003e+01,   2.72000000e+02, ...,\n",
       "           7.49566600e+06,   2.80000000e+01,   0.00000000e+00],\n",
       "        [  6.51500015e+01,   6.51900024e+01,   1.62000000e+03, ...,\n",
       "           7.55248850e+06,   5.00000000e+02,   2.00000000e+00]],\n",
       "\n",
       "       [[  6.52300034e+01,   6.52500000e+01,   2.12300000e+03, ...,\n",
       "           6.99807200e+06,   5.00000000e+00,   2.00000000e+00],\n",
       "        [  6.51800003e+01,   6.52099991e+01,   2.76000000e+02, ...,\n",
       "           7.35185550e+06,   1.00000000e+02,   2.00000000e+00],\n",
       "        [  6.51600037e+01,   6.51800003e+01,   2.72000000e+02, ...,\n",
       "           7.49566600e+06,   2.80000000e+01,   0.00000000e+00],\n",
       "        [  6.51500015e+01,   6.51900024e+01,   1.62000000e+03, ...,\n",
       "           7.55248850e+06,   5.00000000e+02,   2.00000000e+00],\n",
       "        [  6.51100006e+01,   6.51399994e+01,   2.30000000e+01, ...,\n",
       "           7.67502550e+06,   9.60000000e+01,   2.00000000e+00]],\n",
       "\n",
       "       ..., \n",
       "       [[  6.51800003e+01,   6.51900024e+01,   1.46200000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   1.34000000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   1.44000000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.09500000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.09500000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00]],\n",
       "\n",
       "       [[  6.51800003e+01,   6.51900024e+01,   1.34000000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   1.44000000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.09500000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.09500000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.49500000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00]],\n",
       "\n",
       "       [[  6.51800003e+01,   6.51900024e+01,   1.44000000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.09500000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.09500000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.49500000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00],\n",
       "        [  6.51800003e+01,   6.51900024e+01,   4.51700000e+03, ...,\n",
       "           3.72654912e+08,   1.00000000e+02,   0.00000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
