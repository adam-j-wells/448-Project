{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "os.chdir('../Utils/')\n",
    "import featureGenerator\n",
    "from featureGenerator import *\n",
    "os.chdir('../src/')\n",
    "import orderbook_lstm\n",
    "from orderbook_lstm import OrderBookLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features and Response Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../ProjectData/'\n",
    "in_path = data_dir+'msft-orderbook.csv'\n",
    "out_path = data_dir+'msft-orderbook-all.csv'\n",
    "out_path2 = data_dir+'msft-orderbook-final.csv'\n",
    "\n",
    "mergeOrderBookDays(data_dir, out_path, ['msft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createFeatures(out_path, out_path2, response_type = 'Classification')\n",
    "data = pd.read_csv(out_path2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(out_path2)\n",
    "data = data.drop(['datetime', 'direct.last_SRO'], axis = 1)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cols_to_normalize = [col for col in data.columns if col != 'Response']\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "dataset = data.values\n",
    "dataset = dataset.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=5):\n",
    "    dataY = get_one_hot(dataset[look_back+1:,dataset.shape[1]-1].astype(int).reshape(-1),3)\n",
    "    dataX = []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :]    \n",
    "        dataX.append(a)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert response variable to one-hot vectors\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "timesteps = 10\n",
    "n_features = 69\n",
    "n_neurons = 100\n",
    "n_classes = 3\n",
    "n_hidden = 1\n",
    "dropout = None\n",
    "\n",
    "#lstm = OrderBookLSTM(timesteps, n_neurons, (timesteps,n_features), n_classes, n_hidden, dropout)\n",
    "\n",
    "\n",
    "lstm = OrderBookLSTM(10, 100, (10,69), 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = lstm.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats as stats\n",
    "stats.itemfreq(trainX[:,:,68])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.4e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights to change\n",
    "class_weight = {0 : 1.,\n",
    "    1: 10.,\n",
    "    2: 10.} \n",
    "\n",
    "mod.fit(trainX, trainY, \n",
    "          epochs=10,  \n",
    "          batch_size=128, \n",
    "          verbose=1, \n",
    "          class_weight = class_weight)#,\n",
    "          #callbacks=[TensorBoard(log_dir='Logs/', write_graph=True)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions and get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Error\n",
    "preds_training = mod.predict(trainX).argmax(axis=-1)\n",
    "pd.Series(preds_training).value_counts()\n",
    "precision_recall_fscore_support(np.argmax(trainY, axis=1), preds_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Error\n",
    "preds = mod.predict(testX).argmax(axis=-1)\n",
    "pd.Series(preds).value_counts()\n",
    "precision_recall_fscore_support(np.argmax(testY, axis=1), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights to change\n",
    "class_weight = {0 : 1.,\n",
    "    1: 15.,\n",
    "    2: 18.} \n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(5,69), return_sequences=False))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.fit(trainX, trainY, \n",
    "          epochs=2,  \n",
    "          batch_size=10, \n",
    "          #verbose=2, \n",
    "          class_weight = class_weight,\n",
    "          callbacks=[TensorBoard(log_dir='Logs/testlog', write_graph=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(testX).argmax(axis=-1)\n",
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(np.argmax(testY, axis=1), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
