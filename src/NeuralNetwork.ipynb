{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "os.chdir('../Utils/')\n",
    "import featureGenerator\n",
    "from featureGenerator import *\n",
    "os.chdir('../src/')\n",
    "import orderbook_lstm\n",
    "from orderbook_lstm import OrderBookLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features and Response Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['msft-20170417-orderbook.csv', 'msft-20170418-orderbook.csv', 'msft-20170419-orderbook.csv', 'msft-20170420-orderbook.csv', 'msft-20170421-orderbook.csv', 'msft-20170424-orderbook.csv', 'msft-20170425-orderbook.csv', 'msft-20170426-orderbook.csv', 'msft-20170427-orderbook.csv', 'msft-20170428-orderbook.csv']\n",
      "../../ProjectData/msft-20170417-orderbook.csv\n",
      "../../ProjectData/msft-20170418-orderbook.csv\n",
      "../../ProjectData/msft-20170419-orderbook.csv\n",
      "../../ProjectData/msft-20170420-orderbook.csv\n",
      "../../ProjectData/msft-20170421-orderbook.csv\n",
      "../../ProjectData/msft-20170424-orderbook.csv\n",
      "../../ProjectData/msft-20170425-orderbook.csv\n",
      "../../ProjectData/msft-20170426-orderbook.csv\n",
      "../../ProjectData/msft-20170427-orderbook.csv\n",
      "../../ProjectData/msft-20170428-orderbook.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../ProjectData/'\n",
    "in_path = data_dir+'msft-orderbook.csv'\n",
    "out_path = data_dir+'msft-orderbook-all.csv'\n",
    "out_path2 = data_dir+'msft-orderbook-final.csv'\n",
    "\n",
    "mergeOrderBookDays(data_dir, out_path, ['msft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['direct.bid1', 'direct.bid2', 'direct.bid3', 'direct.bid4', 'direct.bid5', 'direct.bid6', 'direct.bid7', 'direct.bid8', 'direct.bid9', 'direct.bid10']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/Desktop/Stanford/MSE 448/448 Project/Utils/featureGenerator.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data['Response'] = response_col\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direct.bid1</th>\n",
       "      <th>direct.bid2</th>\n",
       "      <th>direct.bid3</th>\n",
       "      <th>direct.bid4</th>\n",
       "      <th>direct.bid5</th>\n",
       "      <th>direct.bid6</th>\n",
       "      <th>direct.bid7</th>\n",
       "      <th>direct.bid8</th>\n",
       "      <th>direct.bid9</th>\n",
       "      <th>direct.bid10</th>\n",
       "      <th>...</th>\n",
       "      <th>midPrice_2</th>\n",
       "      <th>midPrice_3</th>\n",
       "      <th>midPrice_4</th>\n",
       "      <th>midPrice_5</th>\n",
       "      <th>midPrice_6</th>\n",
       "      <th>midPrice_7</th>\n",
       "      <th>midPrice_8</th>\n",
       "      <th>midPrice_9</th>\n",
       "      <th>midPrice_10</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.03</td>\n",
       "      <td>65.00</td>\n",
       "      <td>64.96</td>\n",
       "      <td>64.95</td>\n",
       "      <td>64.92</td>\n",
       "      <td>64.90</td>\n",
       "      <td>64.89</td>\n",
       "      <td>64.88</td>\n",
       "      <td>64.86</td>\n",
       "      <td>64.85</td>\n",
       "      <td>...</td>\n",
       "      <td>65.095</td>\n",
       "      <td>65.080</td>\n",
       "      <td>65.080</td>\n",
       "      <td>65.095</td>\n",
       "      <td>65.105</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.130</td>\n",
       "      <td>65.135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.02</td>\n",
       "      <td>65.01</td>\n",
       "      <td>65.00</td>\n",
       "      <td>64.99</td>\n",
       "      <td>64.98</td>\n",
       "      <td>64.97</td>\n",
       "      <td>64.96</td>\n",
       "      <td>64.95</td>\n",
       "      <td>64.92</td>\n",
       "      <td>64.90</td>\n",
       "      <td>...</td>\n",
       "      <td>65.075</td>\n",
       "      <td>65.075</td>\n",
       "      <td>65.080</td>\n",
       "      <td>65.090</td>\n",
       "      <td>65.090</td>\n",
       "      <td>65.095</td>\n",
       "      <td>65.105</td>\n",
       "      <td>65.095</td>\n",
       "      <td>65.125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.10</td>\n",
       "      <td>65.09</td>\n",
       "      <td>65.08</td>\n",
       "      <td>65.06</td>\n",
       "      <td>65.05</td>\n",
       "      <td>65.04</td>\n",
       "      <td>65.02</td>\n",
       "      <td>65.01</td>\n",
       "      <td>65.00</td>\n",
       "      <td>64.99</td>\n",
       "      <td>...</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.110</td>\n",
       "      <td>65.110</td>\n",
       "      <td>65.110</td>\n",
       "      <td>65.110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.10</td>\n",
       "      <td>65.09</td>\n",
       "      <td>65.08</td>\n",
       "      <td>65.06</td>\n",
       "      <td>65.05</td>\n",
       "      <td>65.04</td>\n",
       "      <td>65.03</td>\n",
       "      <td>65.02</td>\n",
       "      <td>65.01</td>\n",
       "      <td>65.00</td>\n",
       "      <td>...</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.115</td>\n",
       "      <td>65.115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.12</td>\n",
       "      <td>65.11</td>\n",
       "      <td>65.10</td>\n",
       "      <td>65.09</td>\n",
       "      <td>65.08</td>\n",
       "      <td>65.06</td>\n",
       "      <td>65.05</td>\n",
       "      <td>65.04</td>\n",
       "      <td>65.03</td>\n",
       "      <td>65.02</td>\n",
       "      <td>...</td>\n",
       "      <td>65.125</td>\n",
       "      <td>65.125</td>\n",
       "      <td>65.125</td>\n",
       "      <td>65.125</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.120</td>\n",
       "      <td>65.120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   direct.bid1  direct.bid2  direct.bid3  direct.bid4  direct.bid5  \\\n",
       "0        65.03        65.00        64.96        64.95        64.92   \n",
       "1        65.02        65.01        65.00        64.99        64.98   \n",
       "2        65.10        65.09        65.08        65.06        65.05   \n",
       "3        65.10        65.09        65.08        65.06        65.05   \n",
       "4        65.12        65.11        65.10        65.09        65.08   \n",
       "\n",
       "   direct.bid6  direct.bid7  direct.bid8  direct.bid9  direct.bid10    ...     \\\n",
       "0        64.90        64.89        64.88        64.86         64.85    ...      \n",
       "1        64.97        64.96        64.95        64.92         64.90    ...      \n",
       "2        65.04        65.02        65.01        65.00         64.99    ...      \n",
       "3        65.04        65.03        65.02        65.01         65.00    ...      \n",
       "4        65.06        65.05        65.04        65.03         65.02    ...      \n",
       "\n",
       "   midPrice_2  midPrice_3  midPrice_4  midPrice_5  midPrice_6  midPrice_7  \\\n",
       "0      65.095      65.080      65.080      65.095      65.105      65.120   \n",
       "1      65.075      65.075      65.080      65.090      65.090      65.095   \n",
       "2      65.120      65.120      65.115      65.115      65.115      65.110   \n",
       "3      65.120      65.120      65.115      65.115      65.115      65.115   \n",
       "4      65.125      65.125      65.125      65.125      65.120      65.120   \n",
       "\n",
       "   midPrice_8  midPrice_9  midPrice_10  Response  \n",
       "0      65.120      65.130       65.135         2  \n",
       "1      65.105      65.095       65.125         1  \n",
       "2      65.110      65.110       65.110         0  \n",
       "3      65.115      65.115       65.115         1  \n",
       "4      65.120      65.120       65.120         1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createFeatures(out_path, out_path2, response_type = 'Classification')\n",
    "data = pd.read_csv(out_path2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(out_path2)\n",
    "data = data.drop(['datetime', 'direct.last_SRO'], axis = 1)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cols_to_normalize = [col for col in data.columns if col != 'Response']\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "dataset = data.values\n",
    "dataset = dataset.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=5):\n",
    "    dataY = get_one_hot(dataset[look_back+1:,dataset.shape[1]-1].astype(int).reshape(-1),3)\n",
    "    dataX = []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :]    \n",
    "        dataX.append(a)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert response variable to one-hot vectors\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "timesteps = 10\n",
    "n_features = 69\n",
    "n_neurons = 100\n",
    "n_classes = 3\n",
    "n_hidden = 1\n",
    "dropout = None\n",
    "\n",
    "#lstm = OrderBookLSTM(timesteps, n_neurons, (timesteps,n_features), n_classes, n_hidden, dropout)\n",
    "\n",
    "\n",
    "lstm = OrderBookLSTM(10, 100, (10,69), 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = lstm.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats as stats\n",
    "stats.itemfreq(trainX[:,:,68])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.4e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights to change\n",
    "class_weight = {0 : 1.,\n",
    "    1: 10.,\n",
    "    2: 10.} \n",
    "\n",
    "mod.fit(trainX, trainY, \n",
    "          epochs=10,  \n",
    "          batch_size=128, \n",
    "          verbose=1, \n",
    "          class_weight = class_weight)#,\n",
    "          #callbacks=[TensorBoard(log_dir='Logs/', write_graph=True)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions and get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Error\n",
    "preds_training = mod.predict(trainX).argmax(axis=-1)\n",
    "pd.Series(preds_training).value_counts()\n",
    "precision_recall_fscore_support(np.argmax(trainY, axis=1), preds_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Error\n",
    "preds = mod.predict(testX).argmax(axis=-1)\n",
    "pd.Series(preds).value_counts()\n",
    "precision_recall_fscore_support(np.argmax(testY, axis=1), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights to change\n",
    "class_weight = {0 : 1.,\n",
    "    1: 15.,\n",
    "    2: 18.} \n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(5,69), return_sequences=False))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.fit(trainX, trainY, \n",
    "          epochs=2,  \n",
    "          batch_size=10, \n",
    "          #verbose=2, \n",
    "          class_weight = class_weight,\n",
    "          callbacks=[TensorBoard(log_dir='Logs/testlog', write_graph=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(testX).argmax(axis=-1)\n",
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(np.argmax(testY, axis=1), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
